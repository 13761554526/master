{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "import sys\n",
    "import cv2\n",
    "import win32gui\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import difflib\n",
    "from datetime import datetime\n",
    "from PIL import ImageGrab, ImageEnhance\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "ocr = PaddleOCR(\n",
    "    use_doc_orientation_classify=False,\n",
    "    use_doc_unwarping=False,\n",
    "    use_textline_orientation=False,\n",
    "    text_det_box_thresh=0.6,\n",
    "    lang='ch',\n",
    "    # 使用轻量模型\n",
    "    text_detection_model_name='PP-OCRv4_mobile_det',  # 检测模型\n",
    "    text_recognition_model_name='PP-OCRv4_mobile_rec',  # 识别模型\n",
    "    text_detection_model_dir='C:\\\\Users\\\\16528\\\\.paddlex\\\\official_models\\\\PP-OCRv4_mobile_det',  # 检测模型\n",
    "    text_recognition_model_dir='C:\\\\Users\\\\16528\\\\.paddlex\\\\official_models\\\\PP-OCRv4_mobile_rec',  # 识别模型\n",
    ")\n",
    "\n",
    "custom_dict_path = \"C:\\\\Users\\\\16528\\\\Desktop\\\\custom_words.txt\"  # 自定义词库路径\n",
    "# ===== 配置 =====\n",
    "TARGET_TITLE = \"短线精灵\"  # 目标窗口标题\n",
    "SAVE_FILE = \"C:\\\\Users\\\\16528\\\\PycharmProjects\\\\PythonProject\\\\save_file\"\n",
    "\n",
    "INTERVAL = 5  # 秒\n",
    "DEBUG_DIR = \"debug_images\"\n",
    "GRID_ROWS = 1  # 行数 (1行)\n",
    "GRID_COLS = 5  # 列数 (8列)\n",
    "GRID_PADDING = 0  # 区域间的像素填充\n",
    "CROP_TOP = 60  # 高度裁剪顶部位置\n",
    "CROP_BOTTOM = 1008  # 高度裁剪底部位置\n",
    "CROP_LEFT = 0  # 宽度裁剪左侧位置\n",
    "CROP_RIGHT = 1920  # 宽度裁剪右侧位置\n",
    "# 数据库连接参数\n",
    "host = \"localhost\"\n",
    "database = \"public\"\n",
    "user = \"root\"\n",
    "password = \"root\"\n",
    "\n",
    "# 获取系统日期\n",
    "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# 新建子目录\n",
    "save_path = os.path.join(SAVE_FILE, date_str)\n",
    "folder_path = os.path.join(SAVE_FILE, date_str)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# 拼接保存文件路径\n",
    "TXT_FILE = os.path.join(save_path, \"大笔买入.txt\")\n",
    "CSV_FILE = os.path.join(save_path, \"大笔买入.csv\")\n",
    "# 输出到文件和控制台\n",
    "output_path = os.path.join(folder_path, \"统计结果.txt\")\n",
    "last_file_path=os.path.join(folder_path, \"last_big_amount.txt\")\n",
    "\n",
    "def find_window_rect(title):\n",
    "    hwnd = win32gui.FindWindow(None, title)\n",
    "    if hwnd == 0:\n",
    "        print(f\"❌ 找不到窗口: {title}\")\n",
    "        return None\n",
    "    return win32gui.GetWindowRect(hwnd)\n",
    "\n",
    "# ====== 读取自定义词库 ======\n",
    "with open(custom_dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    custom_words = [w.strip() for w in f.read().splitlines() if w.strip()]\n",
    "\n",
    "def import_csv_to_mysql(all_rows_csv, host, database, user, password):\n",
    "    try:\n",
    "        # 连接到MySQL数据库\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host,\n",
    "            database=database,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "            # 准备插入语句\n",
    "            insert_query = \"\"\"INSERT INTO short_term_elf (\n",
    "                time, stock_name, description, amount,trade_date\n",
    "            ) VALUES (%s, %s, %s, %s, CURDATE() )\"\"\"\n",
    "\n",
    "            # 插入数据\n",
    "            for row in all_rows_csv:\n",
    "                # 处理空值\n",
    "                processed_row = []\n",
    "                for value in row:\n",
    "                    if value == '' or value is None:\n",
    "                        processed_row.append(None)\n",
    "                    else:\n",
    "                        processed_row.append(value)\n",
    "\n",
    "                cursor.execute(insert_query, processed_row)\n",
    "\n",
    "            connection.commit()\n",
    "            print(f\"成功导入 {cursor.rowcount} 条记录到数据库\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"数据库错误: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL连接已关闭\")\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"优化图像预处理，特别针对小字体\"\"\"\n",
    "    # 转换为灰度\n",
    "    img = img.convert(\"L\")\n",
    "\n",
    "    # 增强对比度\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(1.7)\n",
    "\n",
    "    # 锐化图像\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(1.3)\n",
    "\n",
    "    return img\n",
    "\n",
    "def load_existing_data(file_path):\n",
    "    \"\"\"读取已保存的行，去掉空行\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "def save_unique_txt(rows):\n",
    "    \"\"\"追加保存到 TXT（自动去重）\"\"\"\n",
    "    existing = load_existing_data(TXT_FILE)\n",
    "    new_rows = [r for r in rows if r not in existing]\n",
    "    if not new_rows:\n",
    "        return 0\n",
    "    with open(TXT_FILE, 'a', encoding='utf-8') as f:\n",
    "        for row in new_rows:\n",
    "            f.write(row + \"\\n\")\n",
    "    return len(new_rows)\n",
    "\n",
    "def save_unique_csv(rows):\n",
    "    \"\"\"追加保存到 CSV（自动去重）\"\"\"\n",
    "    existing = load_existing_data(CSV_FILE)\n",
    "    is_new_file = not os.path.exists(CSV_FILE)\n",
    "    with open(CSV_FILE, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if is_new_file:\n",
    "            writer.writerow([\"时间\", \"股票\", \"描述\", \"金额\"])\n",
    "        added_count = 0\n",
    "        unique_rows = []  # 用于返回最终去重后的数据\n",
    "        for row in rows:\n",
    "            row_str = \",\".join(row)\n",
    "            if row_str not in existing:\n",
    "                writer.writerow(row)\n",
    "                unique_rows.append(row)\n",
    "                added_count += 1\n",
    "        if added_count > 0:\n",
    "            import_csv_to_mysql(unique_rows, host, database, user, password)\n",
    "    return added_count\n",
    "\n",
    "def sort_rows_by_time(txt_rows, csv_rows):\n",
    "    \"\"\"\n",
    "    按时间排序数据行\n",
    "    :param txt_rows: [\"09:31:25| 股票 | 描述 | 金额\", ...]\n",
    "    :param csv_rows: [[\"09:31:25\", \"股票\", \"描述\", \"金额\"], ...]\n",
    "    \"\"\"\n",
    "    # 排序 TXT\n",
    "    txt_rows_sorted = sorted(\n",
    "        txt_rows,\n",
    "        key=lambda r: datetime.strptime(r.split(\"|\")[0].strip(), \"%H:%M:%S\"),\n",
    "    )\n",
    "\n",
    "    # 排序 CSV\n",
    "    csv_rows_sorted = sorted(\n",
    "        csv_rows,\n",
    "        key=lambda r: datetime.strptime(r[0].strip(), \"%H:%M:%S\")\n",
    "    )\n",
    "\n",
    "    return txt_rows_sorted, csv_rows_sorted\n",
    "\n",
    "import akshare as ak\n",
    "\n",
    "def get_market_cap_map(df):\n",
    "    # 只取名称和流通市值两列\n",
    "    df_selected = df[[\"名称\", \"流通市值\"]].copy()\n",
    "\n",
    "    # 转换为万元\n",
    "    df_selected[\"流通市值\"] = df_selected[\"流通市值\"] / 10000\n",
    "\n",
    "    # 生成映射字典 {股票名称: 流通市值(万元)}\n",
    "    market_cap_map = dict(zip(df_selected[\"名称\"], df_selected[\"流通市值\"]))\n",
    "\n",
    "    return market_cap_map\n",
    "\n",
    "\n",
    "\n",
    "def match_ocr_lines_to_dict(ocr_lines: list, custom_words: list, cutoff=0.6):\n",
    "    \"\"\"\n",
    "    批量模糊匹配 OCR 文本行到词库\n",
    "\n",
    "    :param ocr_lines: OCR 识别结果列表（每行一个元素）\n",
    "    :param custom_words: 自定义词库（list）\n",
    "    :param cutoff: 相似度阈值（0~1），越高匹配越严格\n",
    "    :return: 匹配结果列表（每个元素是匹配后的字符串）\n",
    "    \"\"\"\n",
    "    # 确保输入是列表且非空\n",
    "    if not isinstance(ocr_lines, list):\n",
    "        raise ValueError(\"ocr_lines 必须是列表类型\")\n",
    "\n",
    "    matched_results = []\n",
    "    for line in ocr_lines:\n",
    "        # 获取最相似的匹配项\n",
    "        matches = difflib.get_close_matches(line, custom_words, n=1, cutoff=cutoff)\n",
    "\n",
    "        if matches:\n",
    "            # 使用匹配到的词库项\n",
    "            matched_results.append(matches[0])\n",
    "        else:\n",
    "            # 没有匹配到则保留原文本\n",
    "            matched_results.append(line)\n",
    "\n",
    "    return matched_results\n",
    "\n",
    "def split_image_into_regions_reverse(cropped):\n",
    "    width = cropped.shape[1]\n",
    "    col_width = width // GRID_COLS\n",
    "    found_data = False\n",
    "    all_rows_txt = []\n",
    "    all_rows_csv = []\n",
    "\n",
    "    # 逆序循环\n",
    "    for i in reversed(range(GRID_COLS)):\n",
    "        start_col = i * col_width\n",
    "        end_col = width if i == GRID_COLS - 1 else (i + 1) * col_width\n",
    "        region = cropped[:, start_col:end_col]\n",
    "\n",
    "        # 分四列\n",
    "        h, w = region.shape[:2]\n",
    "        col1 = region[:, 0:int(w * 0.25)]\n",
    "        col2 = region[:, int(w * 0.25):int(w * 0.50)]\n",
    "        col3 = region[:, int(w * 0.50):int(w * 0.75)]\n",
    "        col4 = region[:, int(w * 0.75):]\n",
    "\n",
    "        # 保存调试图\n",
    "        cv2.imwrite(\"col1_time.png\", col1)\n",
    "        cv2.imwrite(\"col2_stock.png\", col2)\n",
    "        cv2.imwrite(\"col3_desc.png\", col3)\n",
    "        cv2.imwrite(\"col4_money.png\", col4)\n",
    "\n",
    "        image_path_time = r\"C:\\Users\\16528\\PycharmProjects\\PythonProject\\shortline_ths\\col1_time.png\"\n",
    "        image_path_stock = r\"C:\\Users\\16528\\PycharmProjects\\PythonProject\\shortline_ths\\col2_stock.png\"\n",
    "        image_path_desc = r\"C:\\Users\\16528\\PycharmProjects\\PythonProject\\shortline_ths\\col3_desc.png\"\n",
    "        image_path_money = r\"C:\\Users\\16528\\PycharmProjects\\PythonProject\\shortline_ths\\col4_money.png\"\n",
    "\n",
    "        # OCR\n",
    "        time_text = ocr.predict(image_path_time)\n",
    "        stock_text =ocr.predict(image_path_stock)\n",
    "        desc_text = ocr.predict(image_path_desc)\n",
    "        money_text = ocr.predict(image_path_money)\n",
    "\n",
    "        # 按行合并\n",
    "        time_lines = time_text[0]['rec_texts']\n",
    "        stock_lines = stock_text[0]['rec_texts']\n",
    "        stock_lines = match_ocr_lines_to_dict(stock_lines, custom_words, 0.7)\n",
    "        desc_lines = desc_text[0]['rec_texts']\n",
    "        money_lines = money_text[0]['rec_texts']\n",
    "\n",
    "        if not (len(time_lines) == len(stock_lines) == len(money_lines)):\n",
    "            print(f\"错误：第 {i} 区域的四列的行数不一致！\")\n",
    "            return False\n",
    "\n",
    "        rows = min(len(time_lines), len(stock_lines), len(money_lines))\n",
    "        if rows == 0  or (len(time_lines) == 1 and time_lines[0].strip() == \"\"):\n",
    "            continue  # 没数据 → 往前扫描\n",
    "        found_data = True\n",
    "\n",
    "        # 组合行\n",
    "        for j in range(rows):\n",
    "            # 判断是否为卖出\n",
    "            money_val = money_lines[j]\n",
    "            if \"卖出\" in desc_lines[j]:\n",
    "                # 数字前加负号\n",
    "                if not money_val.startswith(\"-\"):\n",
    "                    money_val = \"-\" + money_val\n",
    "\n",
    "            txt_line = f\"{time_lines[j].replace(' ', '')} | {stock_lines[j]} | {desc_lines[j].replace('人', '入')} | {money_val}\"\n",
    "            csv_line = [time_lines[j].replace(\" \", \"\"), stock_lines[j], desc_lines[j].replace(\"人\", \"入\"), money_val]\n",
    "            all_rows_txt.append(txt_line)\n",
    "            all_rows_csv.append(csv_line)\n",
    "\n",
    "        # 检查是否有重复\n",
    "        existing_txt = load_existing_data(TXT_FILE)\n",
    "        if any(r in existing_txt for r in all_rows_txt):\n",
    "            print(f\"⚠️ 第 {i} 区域检测到重复数据 → 停止本轮扫描\")\n",
    "            break  # 停止本次扫描\n",
    "        print(f\"本轮扫描第 {i} 区域检测已完成\")\n",
    "\n",
    "    if not found_data:\n",
    "        print(\"❌ 本轮扫描未识别到任何数据\")\n",
    "    else:\n",
    "        # 按时间排序\n",
    "        all_rows_txt, all_rows_csv = sort_rows_by_time(all_rows_txt, all_rows_csv)\n",
    "        added_txt = save_unique_txt(all_rows_txt)\n",
    "        added_csv = save_unique_csv(all_rows_csv)\n",
    "        print(f\"💾 本轮新增 TXT {added_txt} 行, CSV {added_csv} 行（已按时间排序）\")\n",
    "\n",
    "def output_big_amount_from_file(market_cap_map,file_path, threshold=3000, save_path=\"last_big_amount.txt\"):\n",
    "\n",
    "    \"\"\"\n",
    "    输出成交金额大于 threshold 万元的股票，同时和上一次结果做对比（↑ ↓）\n",
    "    \"\"\"\n",
    "    # 1. 读取上次结果\n",
    "    last_result = {}\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\",\")\n",
    "                if len(parts) == 3:\n",
    "                    name, amount, pct = parts\n",
    "                    try:\n",
    "                        last_result[name] = float(amount)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "    big_amount_stocks = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # 提取成交总金额数字\n",
    "            match_amount = re.search(r\"成交总金额为([\\d.]+)万元\", line)\n",
    "            if match_amount:\n",
    "                total_amount = float(match_amount.group(1))\n",
    "                if total_amount > threshold:\n",
    "                    # 提取第一个非空的股票名称（假设股票名在开头，中文或数字代码都可）\n",
    "                    match_name = re.match(r\"([^\\s，,]+)\", line.strip())\n",
    "                    if match_name:\n",
    "                        stock_name = match_name.group(1)\n",
    "                        pct = round(total_amount/market_cap_map[stock_name] * 100,2)\n",
    "                        if pct > 0.3:\n",
    "                            big_amount_stocks.append((stock_name, total_amount, pct))\n",
    "\n",
    "    # 按金额降序\n",
    "    big_amount_stocks.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # 3. 输出\n",
    "    if big_amount_stocks:\n",
    "        print(f\"\\n💰 成交总金额 > {threshold} 万元的股票：\")\n",
    "        formatted = []\n",
    "        printStockName =[]\n",
    "        for name, amount, pct in big_amount_stocks:\n",
    "            if name in last_result:\n",
    "                cz =amount-last_result[name]\n",
    "                if amount > last_result[name]:\n",
    "                    amount = f\"{amount}🔺🔺🔺{cz}\"\n",
    "                elif amount < last_result[name]:\n",
    "                    amount = f\"{amount}🔽🔽🔽{cz}\"\n",
    "                elif amount == last_result[name]:\n",
    "                    amount = f\"{amount}➖\"\n",
    "            else:\n",
    "                amount = f\"{amount}🔺\"   # 金额染红\n",
    "            if pct > 0.7:\n",
    "                pct = f\"{pct}%❤️\"\n",
    "            formatted.append(f\"{name}：{amount}: {pct}\")\n",
    "            printStockName.append(f\"{name}\")\n",
    "        print(\"  |\" .join(formatted))\n",
    "        print(f\"\\n 满足条件的股票名称{printStockName}\")\n",
    "    else:\n",
    "        print(f\"\\n没有成交总金额大于 {threshold} 万元的股票\")\n",
    "\n",
    "    # 4. 保存本次结果，覆盖文件\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for name, amount, pct in big_amount_stocks:\n",
    "            f.write(f\"{name},{amount},{pct}\\n\")\n",
    "\n",
    "    sys.stdout.flush()  # 双重确保刷新\n",
    "\n",
    "def tj():\n",
    "\n",
    "    # 匹配模式：第一列数字或冒号组合，第二列股票名，第四列金额\n",
    "    # 改进后的正则表达式，支持负号金额匹配\n",
    "    pattern = re.compile(\n",
    "        r\"^\\s*([\\d:]+)\\s*\\|\\s*([\\w\\u4e00-\\u9fa5\\s-]+)\\s*\\|\\s*([\\u4e00-\\u9fa5\\s]+)\\s*\\|\\s*(-?[\\d\\.]+)万\"\n",
    "    )\n",
    "\n",
    "    stock_data = {}\n",
    "\n",
    "    # 遍历目录下所有 txt 文件\n",
    "    txt_files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
    "\n",
    "    for file_path in txt_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if \"|\" not in line:\n",
    "                    continue\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    time_str, stock_name, note, amount_str = match.groups()\n",
    "                    # 保留正负号\n",
    "                    amount = int(amount_str) if not amount_str.startswith('-') else int(amount_str)\n",
    "\n",
    "                    if stock_name not in stock_data:\n",
    "                        stock_data[stock_name] = {\n",
    "                            \"count\": 0,\n",
    "                            \"total\": 0,\n",
    "                            \"early_count\": 0, \"early_amount\": 0,\n",
    "                            \"mid_count\": 0, \"mid_amount\": 0,\n",
    "                            \"late_count\": 0, \"late_amount\": 0,\n",
    "                            \"details\": []\n",
    "                        }\n",
    "\n",
    "                    # 直接按正负累加 → 买入加、卖出减\n",
    "                    stock_data[stock_name][\"count\"] += 1\n",
    "                    stock_data[stock_name][\"total\"] += amount\n",
    "                    stock_data[stock_name][\"details\"].append((time_str, amount))\n",
    "\n",
    "                    # 时间段分类\n",
    "                    try:\n",
    "                        hour, minute, _ = map(int, time_str.split(\":\"))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    time_val = hour * 60 + minute\n",
    "                    if time_val < 9 * 60 + 45:\n",
    "                        stock_data[stock_name][\"early_count\"] += 1\n",
    "                        stock_data[stock_name][\"early_amount\"] += amount\n",
    "                    elif time_val <= 14 * 60 + 45:\n",
    "                        stock_data[stock_name][\"mid_count\"] += 1\n",
    "                        stock_data[stock_name][\"mid_amount\"] += amount\n",
    "                    else:\n",
    "                        stock_data[stock_name][\"late_count\"] += 1\n",
    "                        stock_data[stock_name][\"late_amount\"] += amount\n",
    "\n",
    "\n",
    "    # 按出现次数降序\n",
    "    sorted_data = sorted(stock_data.items(), key=lambda x: x[1][\"total\"], reverse=True)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "        for stock, info in sorted_data:\n",
    "            # 买入 / 卖出总计\n",
    "            buy_count = sum(1 for _, a in info[\"details\"] if a > 0)\n",
    "            buy_amount = sum(a for _, a in info[\"details\"] if a > 0)\n",
    "            sell_count = sum(1 for _, a in info[\"details\"] if a < 0)\n",
    "            sell_amount = sum(abs(a) for _, a in info[\"details\"] if a < 0)\n",
    "\n",
    "            # 成交总金额 = 买入金额 - 卖出金额\n",
    "            total_trades = info[\"count\"]\n",
    "            total_amount = buy_amount - sell_amount  # ← 这里改成差值\n",
    "\n",
    "            # 早盘、中盘、尾盘的买入/卖出细分\n",
    "            def period_stats(start_min, end_min):\n",
    "                trades = [(t, a) for t, a in info[\"details\"]\n",
    "                          if start_min <= (int(t.split(\":\")[0]) * 60 + int(t.split(\":\")[1])) <= end_min]\n",
    "                period_count = len(trades)\n",
    "                # 净额 = 买入 - 卖出\n",
    "                period_amount = sum(a for _, a in trades)\n",
    "                buy_c = sum(1 for _, a in trades if a > 0)\n",
    "                buy_a = sum(a for _, a in trades if a > 0)\n",
    "                sell_c = sum(1 for _, a in trades if a < 0)\n",
    "                sell_a = sum(abs(a) for _, a in trades if a < 0)\n",
    "                return period_count, period_amount, buy_c, buy_a, sell_c, sell_a\n",
    "\n",
    "            early_stats = period_stats(0, 9 * 60 + 44)\n",
    "            mid_stats   = period_stats(9 * 60 + 45, 14 * 60 + 45)\n",
    "            late_stats  = period_stats(14 * 60 + 46, 24 * 60)\n",
    "\n",
    "            details_str = \"，\".join([f\"{t}{'买入' if a>0 else '卖出'}{abs(a)}万元\" for t, a in info[\"details\"]])\n",
    "\n",
    "            out_file.write(\n",
    "                f\"{stock} ，成交{total_trades}次，成交总金额为{total_amount}万元；\"\n",
    "                f\"买入{buy_count}次金额{buy_amount}万元，卖出{sell_count}次金额{sell_amount}万元\\n\"\n",
    "                f\"    早盘：成交{early_stats[0]}次，成交金额{early_stats[1]}万元；买入{early_stats[2]}次金额{early_stats[3]}万元；卖出{early_stats[4]}次金额{early_stats[5]}万元\\n\"\n",
    "                f\"    中盘：成交{mid_stats[0]}次，成交金额{mid_stats[1]}万元；买入{mid_stats[2]}次金额{mid_stats[3]}万元；卖出{mid_stats[4]}次金额{mid_stats[5]}万元\\n\"\n",
    "                f\"    尾盘：成交{late_stats[0]}次，成交金额{late_stats[1]}万元；买入{late_stats[2]}次金额{late_stats[3]}万元；卖出{late_stats[4]}次金额{late_stats[5]}万元\\n\"\n",
    "                f\"    详情：分别在{details_str}\\n\\n\"\n",
    "            )\n",
    "\n",
    "    print(f\"\\n统计完成，结果已保存到: {output_path}\")\n",
    "\n",
    "def parse_text_to_csv(input_file_path, output_file_path=None):\n",
    "    # 如果未指定输出文件路径，则使用输入文件同名但扩展名为.csv\n",
    "    if output_file_path is None:\n",
    "        output_file_path = os.path.splitext(input_file_path)[0] + '.csv'\n",
    "\n",
    "    # 读取输入文件内容\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 分割内容为多个记录（假设每个记录由空行分隔）\n",
    "    records = content.strip().split('\\n\\n')\n",
    "\n",
    "    # 定义CSV表头\n",
    "    headers = [\n",
    "        '股票名称', '总成交次数', '总成交金额(万元)', '总买入次数', '总买入金额(万元)',\n",
    "        '总卖出次数', '总卖出金额(万元)',\n",
    "        '早盘成交次数', '早盘成交金额(万元)', '早盘买入次数', '早盘买入金额(万元)',\n",
    "        '早盘卖出次数', '早盘卖出金额(万元)',\n",
    "        '中盘成交次数', '中盘成交金额(万元)', '中盘买入次数', '中盘买入金额(万元)',\n",
    "        '中盘卖出次数', '中盘卖出金额(万元)',\n",
    "        '尾盘成交次数', '尾盘成交金额(万元)', '尾盘买入次数', '尾盘买入金额(万元)',\n",
    "        '尾盘卖出次数', '尾盘卖出金额(万元)',\n",
    "        '详情'\n",
    "    ]\n",
    "\n",
    "    # 准备所有记录的数据\n",
    "    all_data = []\n",
    "\n",
    "    for record in records:\n",
    "        # 跳过空记录\n",
    "        if not record.strip():\n",
    "            continue\n",
    "\n",
    "        # 提取股票名称\n",
    "        stock_name_match = re.match(r'(\\S+)\\s*，', record)\n",
    "        if not stock_name_match:\n",
    "            continue\n",
    "\n",
    "        stock_name = stock_name_match.group(1)\n",
    "        data = [stock_name]\n",
    "\n",
    "        # 提取总体数据\n",
    "        # 总成交次数和金额\n",
    "        total_trades_match = re.search(r'成交(\\d+)次', record)\n",
    "        total_amount_match = re.search(r'成交总金额为(-?\\d+)万元', record)\n",
    "\n",
    "        # 买入次数和金额（注意：可能为负数）\n",
    "        buy_times_match = re.search(r'买入(\\d+)次', record)\n",
    "        buy_amount_match = re.search(r'买入.*?金额(-?\\d+)万元', record)\n",
    "\n",
    "        # 卖出次数和金额（注意：可能为负数）\n",
    "        sell_times_match = re.search(r'卖出(\\d+)次', record)\n",
    "        sell_amount_match = re.search(r'卖出.*?金额(-?\\d+)万元', record)\n",
    "\n",
    "        # 添加到数据列表\n",
    "        data.append(total_trades_match.group(1) if total_trades_match else '0')\n",
    "        data.append(total_amount_match.group(1) if total_amount_match else '0')\n",
    "        data.append(buy_times_match.group(1) if buy_times_match else '0')\n",
    "        data.append(buy_amount_match.group(1) if buy_amount_match else '0')\n",
    "        data.append(sell_times_match.group(1) if sell_times_match else '0')\n",
    "        data.append(sell_amount_match.group(1) if sell_amount_match else '0')\n",
    "\n",
    "        # 提取各时间段数据\n",
    "        time_periods = ['早盘', '中盘', '尾盘']\n",
    "        for period in time_periods:\n",
    "            # 使用更精确的正则表达式提取每个时间段的数据\n",
    "            period_pattern = f'{period}：.*?成交(\\\\d+)次，成交金额(-?\\\\d+)万元；买入(\\\\d+)次金额(-?\\\\d+)万元；卖出(\\\\d+)次金额(-?\\\\d+)万元'\n",
    "            match = re.search(period_pattern, record)\n",
    "            if match:\n",
    "                data.extend(match.groups())\n",
    "            else:\n",
    "                # 如果没有找到匹配，尝试更宽松的匹配\n",
    "                loose_pattern = f'{period}：.*?成交(\\\\d+)次.*?成交金额(-?\\\\d+)万元.*?买入(\\\\d+)次.*?金额(-?\\\\d+)万元.*?卖出(\\\\d+)次.*?金额(-?\\\\d+)万元'\n",
    "                loose_match = re.search(loose_pattern, record, re.DOTALL)\n",
    "                if loose_match:\n",
    "                    data.extend(loose_match.groups())\n",
    "                else:\n",
    "                    data.extend(['0'] * 6)\n",
    "\n",
    "        # 提取详情\n",
    "        detail_match = re.search(r'详情：(.*?)(?=\\n|$)', record, re.DOTALL)\n",
    "        detail = detail_match.group(1).strip() if detail_match else ''\n",
    "        data.append(detail)\n",
    "\n",
    "        all_data.append(data)\n",
    "\n",
    "    # 写入CSV文件\n",
    "    with open(output_file_path, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(all_data)\n",
    "\n",
    "    print(f\"成功处理 {len(all_data)} 条记录，结果已保存到 {output_file_path}\")\n",
    "    return output_file_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取A股实时行情数据\n",
    "    print(\"📡 开始获取a股实时行情数据...\")\n",
    "    df = ak.stock_zh_a_spot_em()\n",
    "    market_cap_map = get_market_cap_map(df)\n",
    "    print(\"📡 开始实时监控窗口内容...\")\n",
    "    try:\n",
    "        while True:\n",
    "            # 查找目标窗口\n",
    "            rect = find_window_rect(TARGET_TITLE)\n",
    "\n",
    "            if rect:\n",
    "                print(f\"🔍 窗口位置: {rect}\")\n",
    "                # 截取特定区域 (左上角100,100 到右下角500,500)\n",
    "                rect = (0, 0, 1920, 1080)\n",
    "                # 捕获并处理窗口图像\n",
    "                img_np = ImageGrab.grab(bbox=rect)\n",
    "                img_np = preprocess_image(img_np)\n",
    "                # 保存原始图像\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                img_np.save(f\"{DEBUG_DIR}/{timestamp}_raw.png\")\n",
    "                # 读取原图\n",
    "                img = cv2.imread(f\"{DEBUG_DIR}/{timestamp}_raw.png\")\n",
    "                # 全图裁剪\n",
    "                cropped = img[CROP_TOP:CROP_BOTTOM, CROP_LEFT:CROP_RIGHT]\n",
    "                split_image_into_regions_reverse(cropped)\n",
    "                tj()\n",
    "                output_big_amount_from_file(market_cap_map,output_path,1500,last_file_path)\n",
    "                parse_text_to_csv(output_path)\n",
    "                print(f\"下一次截屏采集图像时，停止{INTERVAL}秒\")\n",
    "                sleep(INTERVAL)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 程序已手动停止\")\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
